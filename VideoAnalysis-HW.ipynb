{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "8a09d9ed-d59d-40b2-9b34-4df3f63c6d8f",
   "metadata": {},
   "source": [
    "\n",
    "# YouTube Video Data Analysis: Complete Step-by-Step Guide\n",
    "## A Comprehensive Data Cleaning and Data Analysis Workflow\n",
    "\n",
    "This notebook provides a complete walkthrough of analyzing trending video data, covering:\n",
    "1. Data loading and cleaning\n",
    "2. Feature engineering\n",
    "3. Exploratory data analysis\n",
    "4. Statistical testing\n",
    "5. Country-specific insights\n",
    "\n",
    "**Dataset**: There are two dataset provided: *USvideos.csv* and *GBvideos.csv*\n",
    "\n",
    "\n",
    "## Step 1: Environment Setup (complete one step in this step)\n",
    "First, we'll import all necessary libraries and configure our environment. You might need the following packages:\n",
    "1. numpy\n",
    "2. pandas\n",
    "3. matplotlib.pyplot\n",
    "4. seaborn (as sns)\n",
    "5. glob\n",
    "6. datetime\n",
    "7. scipy\n",
    "\n",
    "Configuration packages/settings:\n",
    "\n",
    "9. %matplotlib inline (IPython magic command)\n",
    "10. sns.set() (Seaborn configuration)\n",
    "11. pd.set_option() (Pandas display options)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "cf636087-f9ce-4fa0-b38f-e960b41aac6f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Environment setup complete!\n"
     ]
    }
   ],
   "source": [
    "# step 1: import all modules\n",
    "\n",
    "#------- complete the step-------------\n",
    "import numpy\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot\n",
    "import seaborn as sns\n",
    "import glob\n",
    "import datetime\n",
    "import scipy\n",
    "#------- complete the step-------------\n",
    "\n",
    "# Configuration\n",
    "%matplotlib inline\n",
    "sns.set(style='whitegrid', palette='muted')\n",
    "pd.set_option('display.max_columns', 100)\n",
    "pd.set_option('display.max_rows', 100)\n",
    "pd.options.mode.chained_assignment = None\n",
    "\n",
    "print(\"Environment setup complete!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6bd3380c-fe8c-4f0a-a684-04bd7137ded1",
   "metadata": {},
   "source": [
    "## Step 2: Data Loading (complete two steps in this step)\n",
    "We'll load all US videos CSV files and GB videos; and combine them into a single dataframe with country identifiers."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "id": "ba63cebe-dd5c-46dd-b317-949dca914f59",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 2 CSV files\n",
      "GB\n",
      "US\n",
      "\n",
      "Sample data from first dataframe:\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>video_id</th>\n",
       "      <th>title</th>\n",
       "      <th>channel_title</th>\n",
       "      <th>category_id</th>\n",
       "      <th>tags</th>\n",
       "      <th>views</th>\n",
       "      <th>likes</th>\n",
       "      <th>dislikes</th>\n",
       "      <th>comment_total</th>\n",
       "      <th>thumbnail_link</th>\n",
       "      <th>date</th>\n",
       "      <th>category</th>\n",
       "      <th>country</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>jt2OHQh0HoQ</td>\n",
       "      <td>Live Apple Event - Apple September Event 2017 ...</td>\n",
       "      <td>Apple Event</td>\n",
       "      <td>28</td>\n",
       "      <td>apple events|apple event|iphone 8|iphone x|iph...</td>\n",
       "      <td>7426393</td>\n",
       "      <td>78240.0</td>\n",
       "      <td>13548.0</td>\n",
       "      <td>705</td>\n",
       "      <td>https://i.ytimg.com/vi/jt2OHQh0HoQ/default_liv...</td>\n",
       "      <td>13.09</td>\n",
       "      <td>News</td>\n",
       "      <td>GB</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>AqokkXoa7uE</td>\n",
       "      <td>Holly and Phillip Meet Samantha the Sex Robot ...</td>\n",
       "      <td>This Morning</td>\n",
       "      <td>24</td>\n",
       "      <td>this morning|interview|holly willoughby|philli...</td>\n",
       "      <td>494203</td>\n",
       "      <td>2651.0</td>\n",
       "      <td>1309.0</td>\n",
       "      <td>0</td>\n",
       "      <td>https://i.ytimg.com/vi/AqokkXoa7uE/default.jpg</td>\n",
       "      <td>13.09</td>\n",
       "      <td>News</td>\n",
       "      <td>GB</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      video_id                                              title  \\\n",
       "0  jt2OHQh0HoQ  Live Apple Event - Apple September Event 2017 ...   \n",
       "1  AqokkXoa7uE  Holly and Phillip Meet Samantha the Sex Robot ...   \n",
       "\n",
       "  channel_title  category_id  \\\n",
       "0   Apple Event           28   \n",
       "1  This Morning           24   \n",
       "\n",
       "                                                tags    views    likes  \\\n",
       "0  apple events|apple event|iphone 8|iphone x|iph...  7426393  78240.0   \n",
       "1  this morning|interview|holly willoughby|philli...   494203   2651.0   \n",
       "\n",
       "   dislikes  comment_total                                     thumbnail_link  \\\n",
       "0   13548.0            705  https://i.ytimg.com/vi/jt2OHQh0HoQ/default_liv...   \n",
       "1    1309.0              0     https://i.ytimg.com/vi/AqokkXoa7uE/default.jpg   \n",
       "\n",
       "    date category country  \n",
       "0  13.09     News      GB  \n",
       "1  13.09     News      GB  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# step 1: read all csv files into list and assign to csv_files\n",
    "csv_files=[]\n",
    "# find all csv files in the current directory\n",
    "for files in glob.glob(\"*.csv\"):\n",
    "    csv_files.append(files)\n",
    "\n",
    "print(f\"Found {len(csv_files)} CSV files\")\n",
    "\n",
    "# Load each CSV with country code\n",
    "dataframes = []\n",
    "\n",
    "# step 2: read csv files into dataframe and append dataframe into dataframes\n",
    "for file in csv_files:\n",
    "    # Extract country code from filename and assign t country_code\n",
    "    country_code=file[:2]\n",
    "    print(country_code)\n",
    "    # read file to dataframe\n",
    "    df = pd.read_csv(file)\n",
    "    if df.shape[1] > 12 :\n",
    "        # column concatenation\n",
    "        df['category'] = df[\"category\"].fillna('') + df.iloc[:, 12].fillna('')\n",
    "        # delete unamed column after concatenation\n",
    "        df = df.drop(df.columns[12], axis=1)    \n",
    "    # adding a new column to the DataFrame (df) that identifies the country\n",
    "    df[\"country\"] = country_code  \n",
    "    dataframes.append(df)\n",
    "    \n",
    "# Verify loading\n",
    "print(\"\\nSample data from first dataframe:\")\n",
    "display(dataframes[0].head(2))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8797134e-01ec-4121-89ec-703d8afd4d46",
   "metadata": {},
   "source": [
    "## Step 3: Data Cleaning (complete one function in this step)\n",
    "We'll clean and standardize data types across all dataframes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "id": "4c3a1c7c-8cdb-46b0-90ec-72eaa2a66d93",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Data types after cleaning:\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "video_id           object\n",
       "title              object\n",
       "channel_title      object\n",
       "category_id        object\n",
       "tags               object\n",
       "views               int64\n",
       "likes               int64\n",
       "dislikes            int64\n",
       "comment_total       int64\n",
       "thumbnail_link     object\n",
       "date              float64\n",
       "category           object\n",
       "country            object\n",
       "dtype: object"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "\n",
    "\"\"\"\n",
    "Step 1: define a function clean_dataframe takes a dataframe parameter. \n",
    "        the function will convert columns : ['video_id', 'title', 'channel_title', 'category_id', 'tags', 'thumbnail_link']\n",
    "        into string, and handling missing Tags\n",
    "\"\"\"  \n",
    "def clean_dataframe(df):\n",
    "    # handle string type\n",
    "    for field in ['video_id', 'title', 'channel_title', 'category_id', 'tags', 'thumbnail_link']:\n",
    "        if field == \"tags\" or field == \"video_id\":\n",
    "            # for tags, seperate and put to list if there is any, make empty list if [none] is there\n",
    "            df[field] = df[field].fillna('').astype(str).apply(lambda x: None if (x == '[none]' or x == '#NAME?') else x.split('|'))\n",
    "        else :\n",
    "            # other string field convert to string\n",
    "            df[field] = df[field].fillna('').astype(str)\n",
    "    for field in ['views','likes','dislikes','comment_total','date']:\n",
    "        if field == \"date\":\n",
    "            # if date, convert to string, then slice to get the first 5 char\n",
    "            df[field] = df[field].astype(str).apply(lambda x: x[:5] if len(x) > 0 else None)\n",
    "            # convert to float64\n",
    "            df[field] = df[field].fillna(0).astype(numpy.float64)\n",
    "        else:\n",
    "            # convert other remaining fields to int64\n",
    "            df[field] = df[field].fillna(0).astype(numpy.int64)\n",
    "    return df\n",
    "\n",
    "# Clean all dataframes\n",
    "cleaned_dataframes = [clean_dataframe(df) for df in dataframes]\n",
    "# Verify cleaning\n",
    "print(\"\\nData types after cleaning:\")\n",
    "display(cleaned_dataframes[0].dtypes)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d788fdb1-3f3e-47f5-8b61-41e1acca23ad",
   "metadata": {},
   "source": [
    "## Step 4: Missing Value Analysis (complete one function in this step)\n",
    "We'll identify and handle any missing values in our dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9319101d-6a4d-4c5b-ac46-61d330971b71",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Missing value summary:\n",
      "                  country  missing_count  missing_percent\n",
      "0        video_id      GB            115         1.438399\n",
      "4            tags      GB            381         4.765478\n",
      "5           views      GB              9         0.112570\n",
      "6           likes      GB             83         1.038149\n",
      "7        dislikes      GB            124         1.550969\n",
      "8   comment_total      GB            181         2.263915\n",
      "13       video_id      US            101         1.262816\n",
      "17           tags      US            491         6.139035\n",
      "18          views      US             10         0.125031\n",
      "19          likes      US             85         1.062766\n",
      "20       dislikes      US            213         2.663166\n",
      "21  comment_total      US            253         3.163291\n",
      "23           date      US           7998       100.000000\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th>country</th>\n",
       "      <th>missing_count</th>\n",
       "      <th>missing_percent</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>video_id</td>\n",
       "      <td>GB</td>\n",
       "      <td>115</td>\n",
       "      <td>1.438399</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>tags</td>\n",
       "      <td>GB</td>\n",
       "      <td>381</td>\n",
       "      <td>4.765478</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>views</td>\n",
       "      <td>GB</td>\n",
       "      <td>9</td>\n",
       "      <td>0.112570</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>likes</td>\n",
       "      <td>GB</td>\n",
       "      <td>83</td>\n",
       "      <td>1.038149</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>dislikes</td>\n",
       "      <td>GB</td>\n",
       "      <td>124</td>\n",
       "      <td>1.550969</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>comment_total</td>\n",
       "      <td>GB</td>\n",
       "      <td>181</td>\n",
       "      <td>2.263915</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>video_id</td>\n",
       "      <td>US</td>\n",
       "      <td>101</td>\n",
       "      <td>1.262816</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>tags</td>\n",
       "      <td>US</td>\n",
       "      <td>491</td>\n",
       "      <td>6.139035</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>views</td>\n",
       "      <td>US</td>\n",
       "      <td>10</td>\n",
       "      <td>0.125031</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>likes</td>\n",
       "      <td>US</td>\n",
       "      <td>85</td>\n",
       "      <td>1.062766</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>dislikes</td>\n",
       "      <td>US</td>\n",
       "      <td>213</td>\n",
       "      <td>2.663166</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>comment_total</td>\n",
       "      <td>US</td>\n",
       "      <td>253</td>\n",
       "      <td>3.163291</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>date</td>\n",
       "      <td>US</td>\n",
       "      <td>7998</td>\n",
       "      <td>100.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                  country  missing_count  missing_percent\n",
       "0        video_id      GB            115         1.438399\n",
       "4            tags      GB            381         4.765478\n",
       "5           views      GB              9         0.112570\n",
       "6           likes      GB             83         1.038149\n",
       "7        dislikes      GB            124         1.550969\n",
       "8   comment_total      GB            181         2.263915\n",
       "13       video_id      US            101         1.262816\n",
       "17           tags      US            491         6.139035\n",
       "18          views      US             10         0.125031\n",
       "19          likes      US             85         1.062766\n",
       "20       dislikes      US            213         2.663166\n",
       "21  comment_total      US            253         3.163291\n",
       "23           date      US           7998       100.000000"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "\"\"\"\n",
    "Step 1: define a function analyze_missing_data\n",
    "        the function returns a missing report that contains country code, missing count and missing percent\n",
    "\"\"\"\n",
    "def analyze_missing_data(df_list, country_codes):\n",
    "    # make template dictionary\n",
    "    report={\"\":[],\"country\":[],\"missing_count\":[],\"missing_percent\":[]}\n",
    "    for df, country in zip(df_list, country_codes):\n",
    "        # total rows of each dataframe\n",
    "        total = len(df) \n",
    "        for col in df.columns:\n",
    "            if df[col].dtype == object:  \n",
    "                # If column contains strings, count None and NaN values\n",
    "                missing = df[col].isnull().sum()\n",
    "            else:\n",
    "                # If column is numeric, count NaN, 0\n",
    "                missing = (df[col] == 0).sum() + df[col].isnull().sum()\n",
    "            # add to dictionary\n",
    "            report[\"\"].append(col)\n",
    "            report[\"country\"].append(country)\n",
    "            report[\"missing_count\"].append(missing)\n",
    "            report[\"missing_percent\"].append(missing*100/total)        \n",
    "    return report\n",
    "\n",
    "# defines a list contains all conuntry code.\n",
    "country_codes=[file[:2] for file in csv_files]\n",
    "\n",
    "# Make dict of missing report\n",
    "missing_report = analyze_missing_data(cleaned_dataframes, country_codes)\n",
    "# turn dict into dataframe\n",
    "missing_report = pd.DataFrame.from_dict(missing_report)\n",
    "\n",
    "# Display results\n",
    "print(\"Missing value summary:\")\n",
    "print(missing_report[missing_report['missing_count'] > 0])\n",
    "display(missing_report[missing_report['missing_count'] > 0])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bee81733-cb55-4f20-99cf-0adddf1c9b08",
   "metadata": {},
   "source": [
    "## Step 5: Data Integration (complete five steps in this step)\n",
    "Combine all country dataframes into one unified dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "59cf8f77-7b70-4e87-bea5-1a38b33335fa",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>video_id</th>\n",
       "      <th>title</th>\n",
       "      <th>channel_title</th>\n",
       "      <th>category_id</th>\n",
       "      <th>tags</th>\n",
       "      <th>views</th>\n",
       "      <th>likes</th>\n",
       "      <th>dislikes</th>\n",
       "      <th>comment_total</th>\n",
       "      <th>thumbnail_link</th>\n",
       "      <th>date</th>\n",
       "      <th>category</th>\n",
       "      <th>country</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>[jt2OHQh0HoQ]</td>\n",
       "      <td>Live Apple Event - Apple September Event 2017 ...</td>\n",
       "      <td>Apple Event</td>\n",
       "      <td>28</td>\n",
       "      <td>[apple events, apple event, iphone 8, iphone x...</td>\n",
       "      <td>7426393</td>\n",
       "      <td>78240</td>\n",
       "      <td>13548</td>\n",
       "      <td>705</td>\n",
       "      <td>https://i.ytimg.com/vi/jt2OHQh0HoQ/default_liv...</td>\n",
       "      <td>13.09</td>\n",
       "      <td>News</td>\n",
       "      <td>GB</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>[AqokkXoa7uE]</td>\n",
       "      <td>Holly and Phillip Meet Samantha the Sex Robot ...</td>\n",
       "      <td>This Morning</td>\n",
       "      <td>24</td>\n",
       "      <td>[this morning, interview, holly willoughby, ph...</td>\n",
       "      <td>494203</td>\n",
       "      <td>2651</td>\n",
       "      <td>1309</td>\n",
       "      <td>0</td>\n",
       "      <td>https://i.ytimg.com/vi/AqokkXoa7uE/default.jpg</td>\n",
       "      <td>13.09</td>\n",
       "      <td>News</td>\n",
       "      <td>GB</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>[YPVcg45W0z4]</td>\n",
       "      <td>My DNA Test Results! I'm WHAT?!</td>\n",
       "      <td>emmablackery</td>\n",
       "      <td>24</td>\n",
       "      <td>[emmablackery, emma blackery, emma, blackery, ...</td>\n",
       "      <td>142819</td>\n",
       "      <td>13119</td>\n",
       "      <td>151</td>\n",
       "      <td>1141</td>\n",
       "      <td>https://i.ytimg.com/vi/YPVcg45W0z4/default.jpg</td>\n",
       "      <td>13.09</td>\n",
       "      <td>News</td>\n",
       "      <td>GB</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>[T_PuZBdT2iM]</td>\n",
       "      <td>getting into a conversation in a language you ...</td>\n",
       "      <td>ProZD</td>\n",
       "      <td>1</td>\n",
       "      <td>[skit, korean, language, conversation, esl, ja...</td>\n",
       "      <td>1580028</td>\n",
       "      <td>65729</td>\n",
       "      <td>1529</td>\n",
       "      <td>3598</td>\n",
       "      <td>https://i.ytimg.com/vi/T_PuZBdT2iM/default.jpg</td>\n",
       "      <td>13.09</td>\n",
       "      <td>News</td>\n",
       "      <td>GB</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>[NsjsmgmbCfc]</td>\n",
       "      <td>Baby Name Challenge!</td>\n",
       "      <td>Sprinkleofglitter</td>\n",
       "      <td>26</td>\n",
       "      <td>[sprinkleofglitter, sprinkle of glitter, baby ...</td>\n",
       "      <td>40592</td>\n",
       "      <td>5019</td>\n",
       "      <td>57</td>\n",
       "      <td>490</td>\n",
       "      <td>https://i.ytimg.com/vi/NsjsmgmbCfc/default.jpg</td>\n",
       "      <td>13.09</td>\n",
       "      <td>News</td>\n",
       "      <td>GB</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7993</th>\n",
       "      <td>[xlu6i6lT_vk]</td>\n",
       "      <td>How Do MASSIVE Sinkholes Form?</td>\n",
       "      <td>Life Noggin</td>\n",
       "      <td>27</td>\n",
       "      <td>[sinkhole, how do sinkholes form, sinkhole in ...</td>\n",
       "      <td>440393</td>\n",
       "      <td>14362</td>\n",
       "      <td>390</td>\n",
       "      <td>1575</td>\n",
       "      <td>https://i.ytimg.com/vi/xlu6i6lT_vk/default.jpg</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Fashion</td>\n",
       "      <td>US</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7994</th>\n",
       "      <td>[qRoVlH1OcI4]</td>\n",
       "      <td>Trump slams Clinton for defending NFL anthem p...</td>\n",
       "      <td>Business Insider</td>\n",
       "      <td>25</td>\n",
       "      <td>[Business Insider, Donald Trump, Hillary Clint...</td>\n",
       "      <td>55762</td>\n",
       "      <td>1265</td>\n",
       "      <td>760</td>\n",
       "      <td>1873</td>\n",
       "      <td>https://i.ytimg.com/vi/qRoVlH1OcI4/default.jpg</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Fashion</td>\n",
       "      <td>US</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7995</th>\n",
       "      <td>[EoejGgUNmVU]</td>\n",
       "      <td>LP - Lost On You (A Night at The McKittrick Ho...</td>\n",
       "      <td>LP</td>\n",
       "      <td>10</td>\n",
       "      <td>[LP, Death Valley, Other People, Lost On You, ...</td>\n",
       "      <td>142908</td>\n",
       "      <td>7088</td>\n",
       "      <td>68</td>\n",
       "      <td>437</td>\n",
       "      <td>https://i.ytimg.com/vi/EoejGgUNmVU/default.jpg</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Fashion</td>\n",
       "      <td>US</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7996</th>\n",
       "      <td>[MT1CMTI0EVw]</td>\n",
       "      <td>Tré Melvin @ #YouTubeBlack FanFest Washington ...</td>\n",
       "      <td>YouTube FanFest</td>\n",
       "      <td>24</td>\n",
       "      <td>[YouTube FanFest, #YTFF, Washington DC, USA, Y...</td>\n",
       "      <td>24532</td>\n",
       "      <td>2148</td>\n",
       "      <td>77</td>\n",
       "      <td>0</td>\n",
       "      <td>https://i.ytimg.com/vi/MT1CMTI0EVw/default.jpg</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Fashion</td>\n",
       "      <td>US</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7997</th>\n",
       "      <td>[AFxLA3RGjnc]</td>\n",
       "      <td>First cosmic event seen in gravitational waves...</td>\n",
       "      <td>National Science Foundation</td>\n",
       "      <td>28</td>\n",
       "      <td>[LIGO, Virgo, collaboration, space, science, n...</td>\n",
       "      <td>144039</td>\n",
       "      <td>1574</td>\n",
       "      <td>59</td>\n",
       "      <td>0</td>\n",
       "      <td>https://i.ytimg.com/vi/AFxLA3RGjnc/default.jpg</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Fashion</td>\n",
       "      <td>US</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>15993 rows × 13 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "           video_id                                              title  \\\n",
       "0     [jt2OHQh0HoQ]  Live Apple Event - Apple September Event 2017 ...   \n",
       "1     [AqokkXoa7uE]  Holly and Phillip Meet Samantha the Sex Robot ...   \n",
       "2     [YPVcg45W0z4]                    My DNA Test Results! I'm WHAT?!   \n",
       "3     [T_PuZBdT2iM]  getting into a conversation in a language you ...   \n",
       "4     [NsjsmgmbCfc]                               Baby Name Challenge!   \n",
       "...             ...                                                ...   \n",
       "7993  [xlu6i6lT_vk]                     How Do MASSIVE Sinkholes Form?   \n",
       "7994  [qRoVlH1OcI4]  Trump slams Clinton for defending NFL anthem p...   \n",
       "7995  [EoejGgUNmVU]  LP - Lost On You (A Night at The McKittrick Ho...   \n",
       "7996  [MT1CMTI0EVw]  Tré Melvin @ #YouTubeBlack FanFest Washington ...   \n",
       "7997  [AFxLA3RGjnc]  First cosmic event seen in gravitational waves...   \n",
       "\n",
       "                    channel_title category_id  \\\n",
       "0                     Apple Event          28   \n",
       "1                    This Morning          24   \n",
       "2                    emmablackery          24   \n",
       "3                           ProZD           1   \n",
       "4               Sprinkleofglitter          26   \n",
       "...                           ...         ...   \n",
       "7993                  Life Noggin          27   \n",
       "7994             Business Insider          25   \n",
       "7995                           LP          10   \n",
       "7996              YouTube FanFest          24   \n",
       "7997  National Science Foundation          28   \n",
       "\n",
       "                                                   tags    views  likes  \\\n",
       "0     [apple events, apple event, iphone 8, iphone x...  7426393  78240   \n",
       "1     [this morning, interview, holly willoughby, ph...   494203   2651   \n",
       "2     [emmablackery, emma blackery, emma, blackery, ...   142819  13119   \n",
       "3     [skit, korean, language, conversation, esl, ja...  1580028  65729   \n",
       "4     [sprinkleofglitter, sprinkle of glitter, baby ...    40592   5019   \n",
       "...                                                 ...      ...    ...   \n",
       "7993  [sinkhole, how do sinkholes form, sinkhole in ...   440393  14362   \n",
       "7994  [Business Insider, Donald Trump, Hillary Clint...    55762   1265   \n",
       "7995  [LP, Death Valley, Other People, Lost On You, ...   142908   7088   \n",
       "7996  [YouTube FanFest, #YTFF, Washington DC, USA, Y...    24532   2148   \n",
       "7997  [LIGO, Virgo, collaboration, space, science, n...   144039   1574   \n",
       "\n",
       "      dislikes  comment_total  \\\n",
       "0        13548            705   \n",
       "1         1309              0   \n",
       "2          151           1141   \n",
       "3         1529           3598   \n",
       "4           57            490   \n",
       "...        ...            ...   \n",
       "7993       390           1575   \n",
       "7994       760           1873   \n",
       "7995        68            437   \n",
       "7996        77              0   \n",
       "7997        59              0   \n",
       "\n",
       "                                         thumbnail_link   date category  \\\n",
       "0     https://i.ytimg.com/vi/jt2OHQh0HoQ/default_liv...  13.09     News   \n",
       "1        https://i.ytimg.com/vi/AqokkXoa7uE/default.jpg  13.09     News   \n",
       "2        https://i.ytimg.com/vi/YPVcg45W0z4/default.jpg  13.09     News   \n",
       "3        https://i.ytimg.com/vi/T_PuZBdT2iM/default.jpg  13.09     News   \n",
       "4        https://i.ytimg.com/vi/NsjsmgmbCfc/default.jpg  13.09     News   \n",
       "...                                                 ...    ...      ...   \n",
       "7993     https://i.ytimg.com/vi/xlu6i6lT_vk/default.jpg    NaN  Fashion   \n",
       "7994     https://i.ytimg.com/vi/qRoVlH1OcI4/default.jpg    NaN  Fashion   \n",
       "7995     https://i.ytimg.com/vi/EoejGgUNmVU/default.jpg    NaN  Fashion   \n",
       "7996     https://i.ytimg.com/vi/MT1CMTI0EVw/default.jpg    NaN  Fashion   \n",
       "7997     https://i.ytimg.com/vi/AFxLA3RGjnc/default.jpg    NaN  Fashion   \n",
       "\n",
       "     country  \n",
       "0         GB  \n",
       "1         GB  \n",
       "2         GB  \n",
       "3         GB  \n",
       "4         GB  \n",
       "...      ...  \n",
       "7993      US  \n",
       "7994      US  \n",
       "7995      US  \n",
       "7996      US  \n",
       "7997      US  \n",
       "\n",
       "[15993 rows x 13 columns]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Combined dataset information:\n",
      "Total videos: 15993\n",
      "Countries: ['GB', 'US']\n"
     ]
    }
   ],
   "source": [
    "# Idea: every scan new one put in dict, if one video have already scan, pass and go to the next iteration\n",
    "# Step 1: Combine all dataframes\n",
    "#------- complete the step-------------\n",
    "frames = [df for df in cleaned_dataframes]\n",
    "combined_df = pd.concat(frames)\n",
    "#------- complete the step-------------\n",
    "\n",
    "# Step 2: Create backup before deduplication\n",
    "#------- complete the step-------------\n",
    "backup_df = combined_df.copy()\n",
    "#------- complete the step-------------\n",
    "\n",
    "# Step 3: Remove duplicate videos (keeping first occurrence) by video_id\n",
    "#------- complete the step-------------\n",
    "\n",
    "\n",
    "#------- complete the step-------------\n",
    "\n",
    "# Step 4: Set video_id as index\n",
    "#------- complete the step-------------\n",
    "\n",
    "\n",
    "#------- complete the step-------------\n",
    "\n",
    "# Final dataset info\n",
    "print(\"\\nCombined dataset information:\")\n",
    "print(f\"Total videos: {len(combined_df)}\")\n",
    "print(f\"Countries: {combined_df['country'].unique().tolist()}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b4ebe25d-3cfe-4546-8355-476643cdddde",
   "metadata": {},
   "source": [
    "## Step 6: Feature Engineering (complete six steps in this step)\n",
    "Create new features to enhance our analysis."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cbc5f39d-ba13-4272-b206-096f709524c6",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Engagement metrics\n",
    "# Step 1: add a column named 'like_ratio', computed as likes/dislikes\n",
    "#------- complete the step-------------\n",
    "\n",
    "\n",
    "#------- complete the step-------------\n",
    "\n",
    "# Step 2: add a column named 'engagement_rate', computed as (likes + dislikes + comment_total)/views\n",
    "#------- complete the step-------------\n",
    "\n",
    "\n",
    "#------- complete the step-------------\n",
    "\n",
    "\n",
    "# Text features\n",
    "# Step 3: add a column named 'title_length', computed as length of title\n",
    "#------- complete the step-------------\n",
    "\n",
    "\n",
    "#------- complete the step-------------\n",
    "\n",
    "# Step 4: add a column named 'title_word_count', computed as number of words in title\n",
    "#------- complete the step-------------\n",
    "\n",
    "\n",
    "#------- complete the step-------------\n",
    "\n",
    "# Step 5: add a column named 'title_has_exclamation', computed as bool value (you can make it 0 or 1) of if title contains exclamation mark\n",
    "#------- complete the step-------------\n",
    "\n",
    "\n",
    "#------- complete the step-------------\n",
    "\n",
    "# Tag analysis\n",
    "# Step 6: add a column named 'tags_count', computed as number of tags \n",
    "#------- complete the step-------------\n",
    "\n",
    "\n",
    "#------- complete the step-------------\n",
    "\n",
    "\n",
    "\n",
    "# Display new features\n",
    "print(\"\\nNew features created:\")\n",
    "display(combined_df[['like_ratio', 'engagement_rate', \n",
    "                    'title_length', 'tags_count']].describe())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aa49aeed-c561-4db0-86bc-040ffc23ae12",
   "metadata": {},
   "source": [
    "## Step 7: Exploratory Data Analysis (complete two steps in this step)\n",
    "Now we'll explore our dataset through visualizations and summary statistics."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "155c4684-230d-4248-b6cc-c3fb3efa98a7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set up the figure\n",
    "plt.figure(figsize=(18, 12))\n",
    "\n",
    "\n",
    "\n",
    "# Plot 1: Views vs. Likes\n",
    "# Step 1: make a dot plot shows views and likes. Take 1000 sample from all countries. x-axis will be views and y-axies will be views.\n",
    "#         using different colors indicate different country. Add legend and plot title.\n",
    "\n",
    "#------- complete the step-------------\n",
    "\n",
    "\n",
    "#------- complete the step-------------\n",
    "\n",
    "# Plot 2: Engagement Rate by Country\n",
    "# Step 2: make a box plot shows different country engagement_rate\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8111cb51-6a00-4abd-a425-8b4df1735fae",
   "metadata": {},
   "source": [
    "## Step 8: Country-Specific Analysis (complete one function in this step)\n",
    "We'll examine trends and patterns for individual countries."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ac0fb26f-2749-410f-81ad-57c64317f1e7",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Step 1: define a function that makes bar plot of country's top 5 category's views\n",
    "\n",
    "def analyze_country(df, country_code):\n",
    "    \"\"\"Generate country-specific analysis\"\"\"\n",
    "\n",
    "    #------- complete the step-------------\n",
    "\n",
    "\n",
    "    #------- complete the step-------------\n",
    "    pass\n",
    "\n",
    "# Analyze sample countries\n",
    "for country in ['US', 'GB']:\n",
    "    analyze_country(combined_df, country)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6fcce40d-ab82-4691-b598-5bdc91bd8b23",
   "metadata": {},
   "source": [
    "## Step 9: Advanced Insights (complete one step in this step)\n",
    "We'll extract deeper insights through more sophisticated analysis."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0d4a30a7-fc52-43ff-93c7-fe2313ffb7bb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 1: can you think of a analysis and visualize it?\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9cc45a0e-b80f-45a1-9223-a49c12c168d8",
   "metadata": {},
   "source": [
    "## Step 10: Saving Results\n",
    "Finally, we'll save our cleaned data and visualizations."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8e0f163e-5187-4b81-a3c8-6360bb1957be",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 1: Save cleaned data into csv file\n",
    "#------- complete the step-------------\n",
    "\n",
    "\n",
    "#------- complete the step-------------\n",
    "\n",
    "print(\"Saved cleaned data to 'cleaned_youtube_trending_data.csv'\")\n",
    "\n",
    "# Step 2: Save top 5 globa category bar plot visualizations\n",
    "#------- complete the step-------------\n",
    "\n",
    "\n",
    "#------- complete the step-------------\n",
    "\n",
    "print(\"Saved visualization to 'top_categories.png'\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "77129ec9-b17d-4aef-8920-96b39dcaf157",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
